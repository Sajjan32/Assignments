{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz6a2x0edlovFzYxbsUCgy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sajjan32/Assignments/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt0QgcnKOot8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import glob\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from scipy.stats import norm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load the dataset from the given file path. Assumes the first column contains the labels\n",
        "    and the remaining columns contain the features.\n",
        "    \"\"\"\n",
        "    data = np.loadtxt(file_path)  # Load space-separated values\n",
        "    labels = data[:, 0].astype(int)  # Extract the first column as labels\n",
        "    features = data[:, 1:] / 255.0  # Extract and normalize features\n",
        "    return features, labels\n",
        "\n",
        "# Specify the directory containing the data files\n",
        "data_directory = '/content/data/'\n",
        "\n",
        "# Use glob to find all training and testing files\n",
        "train_files = glob.glob(data_directory + 'train*.txt')  # Matches files like train0.txt, train1.txt, etc.\n",
        "test_files = glob.glob(data_directory + 'test*.txt')    # Matches files like test0.txt, test1.txt, etc.\n",
        "\n",
        "# Initialize lists for features and labels\n",
        "train_features_list, train_labels_list = [], []\n",
        "test_features_list, test_labels_list = [], []\n",
        "\n",
        "# Load training data\n",
        "for train_file in train_files:\n",
        "    features, labels = load_data(train_file)\n",
        "    train_features_list.append(features)\n",
        "    train_labels_list.append(labels)\n",
        "\n",
        "# Combine all training features and labels\n",
        "train_features = np.vstack(train_features_list)\n",
        "train_labels = np.hstack(train_labels_list)\n",
        "\n",
        "# Load testing data\n",
        "for test_file in test_files:\n",
        "    features, labels = load_data(test_file)\n",
        "    test_features_list.append(features)\n",
        "    test_labels_list.append(labels)\n",
        "\n",
        "# Combine all testing features and labels\n",
        "test_features = np.vstack(test_features_list)\n",
        "test_labels = np.hstack(test_labels_list)\n",
        "\n",
        "# Confirm the data is loaded\n",
        "print(f\"Training data shape: {train_features.shape}, Training labels shape: {train_labels.shape}\")\n",
        "print(f\"Testing data shape: {test_features.shape}, Testing labels shape: {test_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvieCuTOSMb2",
        "outputId": "4a875aba-fc52-4baa-92d2-64e47db68c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 784), Training labels shape: (60000,)\n",
            "Testing data shape: (10000, 784), Testing labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors prediction\n",
        "def knn_predict(train_features, train_labels, test_features, k=1):\n",
        "    \"\"\"\n",
        "    Perform k-Nearest Neighbors classification from scratch.\n",
        "    Args:\n",
        "        train_features: Training feature matrix (2D array).\n",
        "        train_labels: Training labels (1D array).\n",
        "        test_features: Test feature matrix (2D array).\n",
        "        k: Number of nearest neighbors to consider (default is 1).\n",
        "    Returns:\n",
        "        predictions: Predicted labels for the test set.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for test_point in test_features:\n",
        "        # Compute Euclidean distance from test point to all training points\n",
        "        dists = np.linalg.norm(train_features - test_point, axis=1)\n",
        "        # Get indices of the k smallest distances\n",
        "        nearest_indices = np.argsort(dists)[:k]\n",
        "        # Get the labels of the nearest neighbors\n",
        "        nearest_labels = train_labels[nearest_indices]\n",
        "        # Perform majority voting\n",
        "        predicted_label = Counter(nearest_labels).most_common(1)[0][0]\n",
        "        predictions.append(predicted_label)\n",
        "    return np.array(predictions)\n",
        "# Calculate 95% confidence interval\n",
        "def calculate_confidence_interval(accuracy, n):\n",
        "    \"\"\"\n",
        "    Calculate the 95% confidence interval for the accuracy.\n",
        "    Args:\n",
        "        accuracy: The accuracy score.\n",
        "        n: The number of test samples.\n",
        "    Returns:\n",
        "        (lower_bound, upper_bound): Confidence interval bounds.\n",
        "    \"\"\"\n",
        "    z = norm.ppf(0.975)  # 95% confidence level\n",
        "    margin = z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - margin, accuracy + margin\n",
        "\n",
        "# Evaluate K-NN\n",
        "k = 1\n",
        "start_train_time = time.time()\n",
        "predictions = knn_predict(train_features, train_labels, test_features, k=k)\n",
        "end_test_time = time.time()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "confidence_interval = calculate_confidence_interval(accuracy, len(test_labels))\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Print results\n",
        "print(f\"K-NN Results for k={k}:\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"95% Confidence Interval: {confidence_interval[0] * 100:.2f}% - {confidence_interval[1] * 100:.2f}%\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "print(f\"Total Time Taken: {end_test_time - start_train_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp__mxzwTU5A",
        "outputId": "5a3625bd-41bf-4a64-ebb3-0603ac81816d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-NN Results for k=1:\n",
            "Accuracy: 96.91%\n",
            "95% Confidence Interval: 96.57% - 97.25%\n",
            "Confusion Matrix:\n",
            "[[ 973    1    1    0    0    1    3    1    0    0]\n",
            " [   0 1129    3    0    1    1    1    0    0    0]\n",
            " [   7    6  992    5    1    0    2   16    3    0]\n",
            " [   0    1    2  970    1   19    0    7    7    3]\n",
            " [   0    7    0    0  944    0    3    5    1   22]\n",
            " [   1    1    0   12    2  860    5    1    6    4]\n",
            " [   4    2    0    0    3    5  944    0    0    0]\n",
            " [   0   14    6    2    4    0    0  992    0   10]\n",
            " [   6    1    3   14    5   13    3    4  920    5]\n",
            " [   2    5    1    6   10    5    1   11    1  967]]\n",
            "Total Time Taken: 3317.7989 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.stats import norm\n"
      ],
      "metadata": {
        "id": "fkqUKRpCgyye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "\n",
        "# Calculate 95% confidence interval\n",
        "def calculate_confidence_interval(accuracy, n):\n",
        "    \"\"\"\n",
        "    Calculate the 95% confidence interval for the accuracy.\n",
        "    Args:\n",
        "        accuracy: The accuracy score.\n",
        "        n: The number of test samples.\n",
        "    Returns:\n",
        "        (lower_bound, upper_bound): Confidence interval bounds.\n",
        "    \"\"\"\n",
        "    z = norm.ppf(0.975)  # 95% confidence level\n",
        "    margin = z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - margin, accuracy + margin\n",
        "\n",
        "# Evaluation function using preloaded data\n",
        "def evaluate_sklearn_knn_with_preloaded_data(k, train_features, train_labels, test_features, test_labels):\n",
        "    \"\"\"\n",
        "    Evaluate scikit-learn's k-NN classifier using preloaded training and testing data.\n",
        "    Args:\n",
        "        k: Number of nearest neighbors to evaluate (e.g., 1).\n",
        "        train_features: Training feature matrix.\n",
        "        train_labels: Training labels.\n",
        "        test_features: Testing feature matrix.\n",
        "        test_labels: Testing labels.\n",
        "    \"\"\"\n",
        "    # Initialize k-NN classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Measure training time\n",
        "    start_train_time = time.time()\n",
        "    knn.fit(train_features, train_labels)\n",
        "    end_train_time = time.time()\n",
        "    training_time = end_train_time - start_train_time\n",
        "\n",
        "    # Measure testing time\n",
        "    start_test_time = time.time()\n",
        "    predictions = knn.predict(test_features)\n",
        "    end_test_time = time.time()\n",
        "    testing_time = end_test_time - start_test_time\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "    confidence_interval = calculate_confidence_interval(accuracy, len(test_labels))\n",
        "    cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Scikit-learn k-NN Results for k={k}:\")\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"95% Confidence Interval: {confidence_interval[0] * 100:.2f}% - {confidence_interval[1] * 100:.2f}%\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "    print(f\"Testing Time: {testing_time:.4f} seconds\\n\")\n",
        "\n",
        "# Call the function using preloaded data\n",
        "evaluate_sklearn_knn_with_preloaded_data(\n",
        "    k=1,\n",
        "    train_features=train_features,\n",
        "    train_labels=train_labels,\n",
        "    test_features=test_features,\n",
        "    test_labels=test_labels\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TceYWBr0hull",
        "outputId": "de36e6b0-c7b8-4606-c2c2-bd31edcb904d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn k-NN Results for k=1:\n",
            "Accuracy: 96.91%\n",
            "95% Confidence Interval: 96.57% - 97.25%\n",
            "Confusion Matrix:\n",
            "[[ 973    1    1    0    0    1    3    1    0    0]\n",
            " [   0 1129    3    0    1    1    1    0    0    0]\n",
            " [   7    6  992    5    1    0    2   16    3    0]\n",
            " [   0    1    2  970    1   19    0    7    7    3]\n",
            " [   0    7    0    0  944    0    3    5    1   22]\n",
            " [   1    1    0   12    2  860    5    1    6    4]\n",
            " [   4    2    0    0    3    5  944    0    0    0]\n",
            " [   0   14    6    2    4    0    0  992    0   10]\n",
            " [   6    1    3   14    5   13    3    4  920    5]\n",
            " [   2    5    1    6   10    5    1   11    1  967]]\n",
            "Training Time: 0.0644 seconds\n",
            "Testing Time: 37.0930 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ff"
      ],
      "metadata": {
        "id": "-zpmJWEKm1Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data(file_path, binarize=False):\n",
        "    \"\"\"\n",
        "    Load and optionally binarize the dataset from the given file path.\n",
        "    Args:\n",
        "        file_path: Path to the data file.\n",
        "        binarize: If True, binarize the features after normalization.\n",
        "    Returns:\n",
        "        features: Normalized (and optionally binarized) features.\n",
        "        labels: Corresponding labels.\n",
        "    \"\"\"\n",
        "    data = np.loadtxt(file_path)\n",
        "    labels = data[:, 0].astype(int)\n",
        "    features = data[:, 1:] / 255.0  # Normalize to [0, 1]\n",
        "    if binarize:\n",
        "        features[features > 0] = 1\n",
        "    return features, labels\n",
        "\n",
        "def load_all_data(directory_path, file_pattern, binarize=False):\n",
        "    \"\"\"\n",
        "    Load and preprocess all data matching the file pattern in the directory.\n",
        "    Args:\n",
        "        directory_path: Path to the directory containing data files.\n",
        "        file_pattern: File pattern to match (e.g., 'train*.txt').\n",
        "        binarize: If True, binarize the features after normalization.\n",
        "    Returns:\n",
        "        features: Combined features from all files.\n",
        "        labels: Combined labels from all files.\n",
        "    \"\"\"\n",
        "    file_paths = glob.glob(directory_path + file_pattern)\n",
        "    features_list, labels_list = [], []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        features, labels = load_data(file_path, binarize=binarize)\n",
        "        features_list.append(features)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    features = np.vstack(features_list)\n",
        "    labels = np.hstack(labels_list)\n",
        "    return features, labels\n"
      ],
      "metadata": {
        "id": "aIFiqr6Lm3mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing functions\n",
        "def calculate_priors(labels):\n",
        "    return np.array([np.mean(labels == i) for i in range(10)])\n",
        "\n",
        "def calculate_likelihoods(features, labels, alpha=1):\n",
        "    likelihoods = np.zeros((10, features.shape[1], 2))\n",
        "    for i in range(10):\n",
        "        digit_data = features[labels == i]\n",
        "        likelihoods[i, :, 1] = (np.sum(digit_data, axis=0) + alpha) / (digit_data.shape[0] + 2 * alpha)\n",
        "        likelihoods[i, :, 0] = 1 - likelihoods[i, :, 1]\n",
        "    return likelihoods\n",
        "\n",
        "def predict(feature_vector, priors, likelihoods):\n",
        "    posteriors = np.log(priors)\n",
        "    for i in range(10):\n",
        "        posteriors[i] += np.sum(np.log(likelihoods[i, np.arange(feature_vector.shape[0]), feature_vector.astype(int)]))\n",
        "    return np.argmax(posteriors)\n",
        "\n",
        "def calculate_confidence_interval(accuracy, n):\n",
        "    z = norm.ppf(0.975)\n",
        "    margin = z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - margin, accuracy + margin\n",
        "\n",
        "def run_experiment_with_preloaded_data(train_features, train_labels, test_features, test_labels):\n",
        "    print(\"\\nTraining with preloaded data\")\n",
        "\n",
        "    # Training\n",
        "    start_train_time = time.time()\n",
        "    priors = calculate_priors(train_labels)\n",
        "    likelihoods = calculate_likelihoods(train_features, train_labels)\n",
        "    end_train_time = time.time()\n",
        "\n",
        "    # Testing\n",
        "    start_test_time = time.time()\n",
        "    predictions = np.array([predict(test_features[i], priors, likelihoods) for i in range(len(test_labels))])\n",
        "    end_test_time = time.time()\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = np.mean(predictions == test_labels)\n",
        "    confidence_interval = calculate_confidence_interval(accuracy, len(test_labels))\n",
        "    conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "    print(f'95% Confidence Interval: {confidence_interval[0] * 100:.2f}% - {confidence_interval[1] * 100:.2f}%')\n",
        "    print(f'Training Time: {end_train_time - start_train_time:.4f} seconds')\n",
        "    print(f'Testing Time: {end_test_time - start_test_time:.4f} seconds')\n",
        "    print('Confusion Matrix:')\n",
        "    print(conf_matrix)\n",
        "\n",
        "# Example Usage\n",
        "directory_path = '/content/data/'\n",
        "\n",
        "# Load data\n",
        "train_features, train_labels = load_all_data(directory_path, 'train*.txt', binarize=True)\n",
        "test_features, test_labels = load_all_data(directory_path, 'test*.txt', binarize=True)\n",
        "\n",
        "# Run experiment\n",
        "run_experiment_with_preloaded_data(train_features, train_labels, test_features, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wln_FvpqnKIf",
        "outputId": "5508e27f-ca48-4436-f95a-e0666dd4fc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with preloaded data\n",
            "Accuracy: 84.13%\n",
            "95% Confidence Interval: 83.41% - 84.85%\n",
            "Training Time: 0.1842 seconds\n",
            "Testing Time: 2.2876 seconds\n",
            "Confusion Matrix:\n",
            "[[ 887    0    4    7    2   41   16    1   22    0]\n",
            " [   0 1085   10    5    0    9    6    0   19    1]\n",
            " [  19    8  852   29   17    4   32   14   55    2]\n",
            " [   5   15   34  844    0   13    9   15   49   26]\n",
            " [   2    6    4    0  795    4   21    1   23  126]\n",
            " [  23   12    7  129   30  627   16    8   21   19]\n",
            " [  18   18   15    2   13   35  851    0    6    0]\n",
            " [   1   24   14    4   15    0    0  871   27   72]\n",
            " [  16   23   13   76   17   22    7    6  758   36]\n",
            " [   9   13    5    9   74    8    0   24   24  843]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "metadata": {
        "id": "0M-pg4CMo4VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_sklearn(train_features, train_labels, test_features, test_labels):\n",
        "    print(\"\\nTraining with Scikit-learn's Bernoulli Naive Bayes\")\n",
        "\n",
        "    # Training\n",
        "    start_train_time = time.time()\n",
        "    model = BernoulliNB()\n",
        "    model.fit(train_features, train_labels)\n",
        "    end_train_time = time.time()\n",
        "\n",
        "    # Testing\n",
        "    start_test_time = time.time()\n",
        "    predictions = model.predict(test_features)\n",
        "    end_test_time = time.time()\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "    confidence_interval = calculate_confidence_interval(accuracy, len(test_labels))\n",
        "    conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "    print(f'95% Confidence Interval: {confidence_interval[0] * 100:.2f}% - {confidence_interval[1] * 100:.2f}%')\n",
        "    print(f'Training Time: {end_train_time - start_train_time:.4f} seconds')\n",
        "    print(f'Testing Time: {end_test_time - start_test_time:.4f} seconds')\n",
        "    print('Confusion Matrix:')\n",
        "    print(conf_matrix)\n",
        "\n",
        "# Example Usage\n",
        "directory_path = '/content/data/'\n",
        "\n",
        "# Load data\n",
        "train_features, train_labels = load_all_data(directory_path, 'train*.txt', binarize=True)\n",
        "test_features, test_labels = load_all_data(directory_path, 'test*.txt', binarize=True)\n",
        "\n",
        "# Run experiment\n",
        "run_experiment_sklearn(train_features, train_labels, test_features, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPQjEllCnZBf",
        "outputId": "c9ac438d-9e7b-4516-c666-3b7de5ebac84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Scikit-learn's Bernoulli Naive Bayes\n",
            "Accuracy: 84.13%\n",
            "95% Confidence Interval: 83.41% - 84.85%\n",
            "Training Time: 0.6503 seconds\n",
            "Testing Time: 0.1127 seconds\n",
            "Confusion Matrix:\n",
            "[[ 887    0    4    7    2   41   16    1   22    0]\n",
            " [   0 1085   10    5    0    9    6    0   19    1]\n",
            " [  19    8  852   29   17    4   32   14   55    2]\n",
            " [   5   15   34  844    0   13    9   15   49   26]\n",
            " [   2    6    4    0  795    4   21    1   23  126]\n",
            " [  23   12    7  129   30  627   16    8   21   19]\n",
            " [  18   18   15    2   13   35  851    0    6    0]\n",
            " [   1   24   14    4   15    0    0  871   27   72]\n",
            " [  16   23   13   76   17   22    7    6  758   36]\n",
            " [   9   13    5    9   74    8    0   24   24  843]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis\n",
        "\n",
        "\n",
        "1.   **Accuracy**:                                                          \n",
        "               Both implementations achieved identical accuracy of 84.13%, which validates the correctness of the custom implementation compared to the Scikit-learn library.\n",
        "2.   **95% Confidence Interval**:                                           \n",
        "               Both implementations produced the same confidence interval range, 83.41% - 84.85%, confirming consistent statistical results.\n",
        "\n",
        "\n",
        "3.  **Training and Testing Time:**\n",
        "                  The custom implementation had a faster training time (0.1842 seconds) compared to Scikit-learn (0.6503 seconds).However, Scikit-learn's testing time (0.1127 seconds) was significantly faster than the custom implementation (2.2876 seconds).\n",
        "                  The difference in testing time highlights the efficiency of Scikit-learn's optimized internal algorithms.\n",
        "4.   **Confusion Matrix: **\n",
        "                  The confusion matrices for both implementations are identical, showing consistent classification performance across all digit classes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8RJHWeq1rXp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "import glob"
      ],
      "metadata": {
        "id": "CoGSP70wp4U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    data = np.loadtxt(file_path)\n",
        "    labels = data[:, 0].astype(int)  # First column contains the labels\n",
        "    features = data[:, 1:] / 255.0  # Normalize features to [0, 1]\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "nNn7JHZ6rdTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_confidence_interval(accuracy, n):\n",
        "    z = norm.ppf(0.975)  # 95% confidence level\n",
        "    margin = z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - margin, accuracy + margin"
      ],
      "metadata": {
        "id": "V-3avdW2rrW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sigmoid function and its derivative\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "    return sigmoid(z) * (1 - sigmoid(z))\n",
        "\n",
        "# Initialize weights\n",
        "def initialize_weights(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(input_size, hidden_size) * np.sqrt(1. / input_size)  # Xavier init for W1\n",
        "    b1 = np.zeros(hidden_size)  # Bias for hidden layer\n",
        "    W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1. / hidden_size)  # Xavier init for W2\n",
        "    b2 = np.zeros(output_size)  # Bias for output layer\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "\n",
        "def load_mnist_data(file_paths):\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    for file_path in file_paths:\n",
        "        features, labels = load_data(file_path)\n",
        "        X_list.append(features)\n",
        "        y_list.append(labels)\n",
        "    X = np.vstack(X_list)\n",
        "    y = np.hstack(y_list)\n",
        "    return X, y\n",
        "\n",
        "# One-hot encode labels\n",
        "def one_hot_encode(labels, num_classes=10):\n",
        "    encoded = np.zeros((labels.size, num_classes))\n",
        "    encoded[np.arange(labels.size), labels] = 1\n",
        "    return encoded\n",
        "\n",
        "# Neural network parameters\n",
        "learning_rate = 0.01\n",
        "num_epochs = 379\n",
        "hidden_units = 5  # Hidden layer size\n",
        "num_features = 784  # 28x28 pixels\n",
        "num_classes = 10  # Digits 0-9\n",
        "\n",
        "# Initialize weights\n",
        "W1, b1, W2, b2 = initialize_weights(num_features, hidden_units, num_classes)\n",
        "training_errors = []\n",
        "epoch_accuracies = []\n",
        "\n",
        "# Load training and testing data\n",
        "train_files = glob.glob('/content/data/train*.txt')\n",
        "\n",
        "\n",
        "train_features, train_labels = load_mnist_data(train_files)\n",
        "test_features, test_labels = load_mnist_data(test_files)\n",
        "train_labels_one_hot = one_hot_encode(train_labels, num_classes=num_classes)\n",
        "test_files = glob.glob('/content/data/test*.txt')\n",
        "test_features, test_labels = load_mnist_data(test_files)\n",
        "\n",
        "# Training the neural network\n",
        "start_train_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_error = 0\n",
        "    for i in range(train_features.shape[0]):\n",
        "        x_i = train_features[i]  # Single training example\n",
        "        t_i = train_labels_one_hot[i]  # True label in one-hot encoding\n",
        "\n",
        "        # Forward pass\n",
        "        z1 = np.dot(x_i, W1) + b1  # Input to hidden layer\n",
        "        a1 = sigmoid(z1)  # Output from hidden layer\n",
        "        z2 = np.dot(a1, W2) + b2  # Input to output layer\n",
        "        o = sigmoid(z2)  # Final output\n",
        "\n",
        "        # Compute error\n",
        "        error = t_i - o\n",
        "        sample_error = 0.5 * np.sum(error ** 2)\n",
        "        epoch_error += sample_error\n",
        "\n",
        "        # Backpropagation\n",
        "        delta2 = error * sigmoid_derivative(z2)  # Error for output layer\n",
        "        delta1 = np.dot(delta2, W2.T) * sigmoid_derivative(z1)  # Error for hidden layer\n",
        "\n",
        "        # Update weights and biases\n",
        "        W2 += learning_rate * np.outer(a1, delta2)\n",
        "        b2 += learning_rate * delta2\n",
        "        W1 += learning_rate * np.outer(x_i, delta1)\n",
        "        b1 += learning_rate * delta1\n",
        "\n",
        "    training_errors.append(epoch_error / train_features.shape[0])\n",
        "end_train_time = time.time()\n",
        "\n",
        "# Testing the neural network\n",
        "start_test_time = time.time()\n",
        "z1_test = np.dot(test_features, W1) + b1\n",
        "a1_test = sigmoid(z1_test)\n",
        "z2_test = np.dot(a1_test, W2) + b2\n",
        "o_test = sigmoid(z2_test)\n",
        "y_pred = np.argmax(o_test, axis=1)\n",
        "end_test_time = time.time()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "confidence_interval = calculate_confidence_interval(accuracy, len(test_labels))\n",
        "conf_matrix = confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nFinal Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"95% Confidence Interval: {confidence_interval[0] * 100:.2f}% - {confidence_interval[1] * 100:.2f}%\")\n",
        "print(f\"Training Time: {end_train_time - start_train_time:.4f} seconds\")\n",
        "print(f\"Testing Time: {end_test_time - start_test_time:.4f} seconds\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "45ubx7N2r0Cd",
        "outputId": "900a3dd5-1f62-4049-dcbc-514d7ac3751b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "need at least one array to concatenate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a2c0954632d6>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/train*.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtest_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/test*.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a2c0954632d6>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_paths)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlabels_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path, binarize=False):\n",
        "    \"\"\"\n",
        "    Load and optionally binarize the dataset from the given file path.\n",
        "    Args:\n",
        "        file_path: Path to the data file.\n",
        "        binarize: If True, binarize the features after normalization.\n",
        "    Returns:\n",
        "        features: Normalized (and optionally binarized) features.\n",
        "        labels: Corresponding labels.\n",
        "    \"\"\"\n",
        "    data = np.loadtxt(file_path)\n",
        "    labels = data[:, 0].astype(int)\n",
        "    features = data[:, 1:] / 255.0  # Normalize to [0, 1]\n",
        "    if binarize:\n",
        "        features[features > 0] = 1\n",
        "    return features, labels\n",
        "\n",
        "def load_all_data(directory_path, file_pattern, binarize=False):\n",
        "    \"\"\"\n",
        "    Load and preprocess all data matching the file pattern in the directory.\n",
        "    Args:\n",
        "        directory_path: Path to the directory containing data files.\n",
        "        file_pattern: File pattern to match (e.g., 'train*.txt').\n",
        "        binarize: If True, binarize the features after normalization.\n",
        "    Returns:\n",
        "        features: Combined features from all files.\n",
        "        labels: Combined labels from all files.\n",
        "    \"\"\"\n",
        "    file_paths = glob.glob(directory_path + file_pattern)\n",
        "    features_list, labels_list = [], []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        features, labels = load_data(file_path, binarize=binarize)\n",
        "        features_list.append(features)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    features = np.vstack(features_list)\n",
        "    labels = np.hstack(labels_list)\n",
        "    return features, labels\n"
      ],
      "metadata": {
        "id": "3YB42uRhxzeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "\n",
        "def load_data(file_paths):\n",
        "    \"\"\"\n",
        "    Load and preprocess data from multiple files.\n",
        "    Args:\n",
        "        file_paths: List of file paths to load.\n",
        "    Returns:\n",
        "        features: Combined feature matrix.\n",
        "        labels: Combined label vector.\n",
        "    \"\"\"\n",
        "    features_list, labels_list = [], []\n",
        "    for file_path in file_paths:\n",
        "        data = np.loadtxt(file_path)\n",
        "        labels = data[:, 0].astype(int)\n",
        "        features = data[:, 1:] / 255.0  # Normalize to [0, 1]\n",
        "        features_list.append(features)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    features = np.vstack(features_list)\n",
        "    labels = np.hstack(labels_list)\n",
        "    return features, labels\n",
        "\n",
        "# Load train and test data\n",
        "train_files = glob.glob('/content/data/train*.txt')\n",
        "test_files = glob.glob('/content/data/test*.txt')\n",
        "train_features, train_labels = load_data(train_files)\n",
        "test_features, test_labels = load_data(test_files)\n",
        "\n",
        "# Define utility functions\n",
        "def initialize_weights(input_dim, hidden_units, output_units):\n",
        "    W1 = np.random.randn(hidden_units, input_dim) * 0.01\n",
        "    b1 = np.zeros((hidden_units, 1))\n",
        "    W2 = np.random.randn(output_units, hidden_units) * 0.01\n",
        "    b2 = np.zeros((output_units, 1))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "def sigmoid_derivative(Z):\n",
        "    return sigmoid(Z) * (1 - sigmoid(Z))\n",
        "\n",
        "def softmax(Z):\n",
        "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
        "\n",
        "def compute_loss(Y, Y_hat):\n",
        "    m = Y.shape[1]\n",
        "    loss = np.mean((Y_hat - Y) ** 2)\n",
        "    return loss\n",
        "\n",
        "def forward_propagation(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    cache = (Z1, A1, Z2, A2)\n",
        "    return A2, cache\n",
        "\n",
        "def backward_propagation(X, Y, cache, W1, W2):\n",
        "    Z1, A1, Z2, A2 = cache\n",
        "    m = X.shape[1]\n",
        "\n",
        "    dZ2 = 2 * (A2 - Y) / m\n",
        "    dW2 = np.dot(dZ2, A1.T)\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid_derivative(Z1)\n",
        "    dW1 = np.dot(dZ1, X.T)\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def one_hot_encode(labels, num_classes):\n",
        "    encoded = np.zeros((num_classes, labels.size))\n",
        "    encoded[labels, np.arange(labels.size)] = 1\n",
        "    return encoded\n",
        "\n",
        "# Train and evaluate the ANN\n",
        "def train_and_evaluate_ann(train_features, train_labels, test_features, test_labels, hidden_units=5, learning_rate=0.01, epochs=379):\n",
        "    num_classes = 10\n",
        "    input_dim = train_features.shape[1]\n",
        "\n",
        "    # Initialize weights\n",
        "    W1, b1, W2, b2 = initialize_weights(input_dim, hidden_units, num_classes)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    train_labels_encoded = one_hot_encode(train_labels, num_classes)\n",
        "    test_labels_encoded = one_hot_encode(test_labels, num_classes)\n",
        "\n",
        "    # Training\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        A2, cache = forward_propagation(train_features.T, W1, b1, W2, b2)\n",
        "        loss = compute_loss(train_labels_encoded, A2)\n",
        "        dW1, db1, dW2, db2 = backward_propagation(train_features.T, train_labels_encoded, cache, W1, W2)\n",
        "        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs} - Loss: {loss:.4f}\")\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Testing\n",
        "    start_time = time.time()\n",
        "    A2_test, _ = forward_propagation(test_features.T, W1, b1, W2, b2)\n",
        "    predictions = np.argmax(A2_test, axis=0)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Confusion matrix and accuracy\n",
        "    conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "    accuracy = np.mean(predictions == test_labels)\n",
        "\n",
        "    # Accuracy with 95% confidence interval\n",
        "    n = len(test_labels)\n",
        "    z = norm.ppf(0.975)  # 95% confidence\n",
        "    ci_lower = accuracy - z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    ci_upper = accuracy + z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"confidence_interval\": (ci_lower, ci_upper),\n",
        "        \"confusion_matrix\": conf_matrix,\n",
        "        \"training_time\": training_time,\n",
        "        \"testing_time\": testing_time,\n",
        "    }\n",
        "\n",
        "# Run the experiment\n",
        "results = train_and_evaluate_ann(train_features, train_labels, test_features, test_labels, hidden_units=5, learning_rate=0.01, epochs=379)\n",
        "\n",
        "# Output results\n",
        "print(\"Accuracy: {:.2f}%\".format(results[\"accuracy\"] * 100))\n",
        "print(\"95% Confidence Interval: ({:.2f}%, {:.2f}%)\".format(results[\"confidence_interval\"][0] * 100, results[\"confidence_interval\"][1] * 100))\n",
        "print(\"Confusion Matrix:\\n\", results[\"confusion_matrix\"])\n",
        "print(\"Training Time: {:.2f} seconds\".format(results[\"training_time\"]))\n",
        "print(\"Testing Time: {:.2f} seconds\".format(results[\"testing_time\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIRSoHXszkJr",
        "outputId": "ac86f74d-803a-4ec0-930f-c13959773024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/379 - Loss: 0.0900\n",
            "Epoch 50/379 - Loss: 0.0900\n",
            "Epoch 100/379 - Loss: 0.0900\n",
            "Epoch 150/379 - Loss: 0.0900\n",
            "Epoch 200/379 - Loss: 0.0900\n",
            "Epoch 250/379 - Loss: 0.0900\n",
            "Epoch 300/379 - Loss: 0.0900\n",
            "Epoch 350/379 - Loss: 0.0899\n",
            "Accuracy: 11.35%\n",
            "95% Confidence Interval: (10.73%, 11.97%)\n",
            "Confusion Matrix:\n",
            " [[   0  980    0    0    0    0    0    0    0    0]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [   0 1032    0    0    0    0    0    0    0    0]\n",
            " [   0 1010    0    0    0    0    0    0    0    0]\n",
            " [   0  982    0    0    0    0    0    0    0    0]\n",
            " [   0  892    0    0    0    0    0    0    0    0]\n",
            " [   0  958    0    0    0    0    0    0    0    0]\n",
            " [   0 1028    0    0    0    0    0    0    0    0]\n",
            " [   0  974    0    0    0    0    0    0    0    0]\n",
            " [   0 1009    0    0    0    0    0    0    0    0]]\n",
            "Training Time: 124.41 seconds\n",
            "Testing Time: 0.02 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import glob\n",
        "\n",
        "# Helper functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def one_hot_encode(labels, num_classes=10):\n",
        "    return np.eye(num_classes)[labels]\n",
        "\n",
        "def calculate_confidence_interval(accuracy, n, confidence=0.95):\n",
        "    Z = 1.96  # For 95% confidence level\n",
        "    ci_half_width = Z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - ci_half_width, accuracy + ci_half_width\n",
        "\n",
        "# Load data\n",
        "def load_data(file_path):\n",
        "    data = np.loadtxt(file_path)\n",
        "    X = data[:, 1:] / 255.0  # Normalize pixel values to [0, 1]\n",
        "    y = one_hot_encode(data[:, 0].astype(int))  # One-hot encode labels\n",
        "    return X, y\n",
        "\n",
        "# Initialize parameters\n",
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(hidden_size, input_size) * 0.01\n",
        "    b1 = np.zeros((hidden_size, 1))\n",
        "    W2 = np.random.randn(output_size, hidden_size) * 0.01\n",
        "    b2 = np.zeros((output_size, 1))\n",
        "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
        "\n",
        "# Forward pass\n",
        "def forward_propagation(X, parameters):\n",
        "    W1, b1, W2, b2 = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    return {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
        "\n",
        "# Compute least squares error\n",
        "def compute_loss(Y, A2):\n",
        "    return 0.5 * np.sum((Y - A2) ** 2)\n",
        "\n",
        "# Backpropagation\n",
        "def backpropagation(X, Y, forward_cache, parameters):\n",
        "    W2 = parameters[\"W2\"]\n",
        "    A1, A2 = forward_cache[\"A1\"], forward_cache[\"A2\"]\n",
        "\n",
        "    # Gradients\n",
        "    dZ2 = A2 - Y\n",
        "    dW2 = np.dot(dZ2, A1.T)\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dZ1 = np.dot(W2.T, dZ2) * sigmoid_derivative(A1)\n",
        "    dW1 = np.dot(dZ1, X.T)\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "\n",
        "# Update parameters\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    parameters[\"W1\"] -= learning_rate * grads[\"dW1\"]\n",
        "    parameters[\"b1\"] -= learning_rate * grads[\"db1\"]\n",
        "    parameters[\"W2\"] -= learning_rate * grads[\"dW2\"]\n",
        "    parameters[\"b2\"] -= learning_rate * grads[\"db2\"]\n",
        "    return parameters\n",
        "\n",
        "# Train neural network\n",
        "def train_neural_network(training_files, input_size, hidden_size, output_size, learning_rate, epochs):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
        "    average_losses = []\n",
        "\n",
        "    # Load all training data\n",
        "    X_train, Y_train = [], []\n",
        "    for file in training_files:\n",
        "        X, Y = load_data(file)\n",
        "        X_train.append(X)\n",
        "        Y_train.append(Y)\n",
        "    X_train = np.vstack(X_train)  # Combine all training data\n",
        "    Y_train = np.vstack(Y_train)  # Combine all training labels\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)  # Shuffle data indices for SGD\n",
        "\n",
        "        for idx in indices:\n",
        "            # Select a random sample\n",
        "            X_sample = X_train[idx].reshape(-1, 1)\n",
        "            Y_sample = Y_train[idx].reshape(-1, 1)\n",
        "\n",
        "            # Forward pass\n",
        "            forward_cache = forward_propagation(X_sample, parameters)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = compute_loss(Y_sample, forward_cache[\"A2\"])\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backpropagation\n",
        "            grads = backpropagation(X_sample, Y_sample, forward_cache, parameters)\n",
        "\n",
        "            # Update parameters\n",
        "            parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        average_loss = total_loss / X_train.shape[0]\n",
        "        average_losses.append(average_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {average_loss:.6f}\")\n",
        "\n",
        "    return parameters, average_losses\n",
        "\n",
        "# Test neural network\n",
        "def test_neural_network(testing_files, parameters):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for file in testing_files:\n",
        "        X, Y = load_data(file)\n",
        "        forward_cache = forward_propagation(X.T, parameters)\n",
        "        A2 = forward_cache[\"A2\"]\n",
        "        predicted_labels = np.argmax(A2, axis=0)\n",
        "        true_labels.extend(np.argmax(Y, axis=1))\n",
        "        predictions.extend(predicted_labels)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "    return accuracy, conf_matrix, true_labels, predictions\n",
        "\n",
        "# File paths\n",
        "# training_files = [f'content/data/train{i}.txt' for i in range(10)]\n",
        "# testing_files = [f'content/data/test{i}.txt' for i in range(10)]\n",
        "training_files = glob.glob('/content/data/train*.txt')\n",
        "testing_files = glob.glob('/content/data/test*.txt')\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 784\n",
        "hidden_size = 5\n",
        "output_size = 10\n",
        "learning_rate = 0.02\n",
        "epochs = 100\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "parameters, average_losses = train_neural_network(training_files, input_size, hidden_size, output_size, learning_rate, epochs)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Measure testing time\n",
        "start_test_time = time.time()\n",
        "accuracy, conf_matrix, true_labels, predictions = test_neural_network(testing_files, parameters)\n",
        "end_test_time = time.time()\n",
        "testing_time = end_test_time - start_test_time\n",
        "\n",
        "# Calculate confidence interval\n",
        "lower_ci, upper_ci = calculate_confidence_interval(accuracy, len(true_labels))\n",
        "\n",
        "# Results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Testing Time: {testing_time:.2f} seconds\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"95% Confidence Interval: ({lower_ci:.4f}, {upper_ci:.4f})\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot average loss per epoch\n",
        "plt.plot(average_losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Average Loss\")\n",
        "plt.title(\"Average Loss Over Epochs\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_2L-Dp_qwR-M",
        "outputId": "7d69f63b-c06c-4ac1-d201-fd35380ac04a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Average Loss: 0.228575\n",
            "Epoch 2/100, Average Loss: 0.134108\n",
            "Epoch 3/100, Average Loss: 0.116171\n",
            "Epoch 4/100, Average Loss: 0.111582\n",
            "Epoch 5/100, Average Loss: 0.108772\n",
            "Epoch 6/100, Average Loss: 0.107490\n",
            "Epoch 7/100, Average Loss: 0.106499\n",
            "Epoch 8/100, Average Loss: 0.105218\n",
            "Epoch 9/100, Average Loss: 0.104389\n",
            "Epoch 10/100, Average Loss: 0.104129\n",
            "Epoch 11/100, Average Loss: 0.103586\n",
            "Epoch 12/100, Average Loss: 0.103081\n",
            "Epoch 13/100, Average Loss: 0.102620\n",
            "Epoch 14/100, Average Loss: 0.102515\n",
            "Epoch 15/100, Average Loss: 0.101863\n",
            "Epoch 16/100, Average Loss: 0.102136\n",
            "Epoch 17/100, Average Loss: 0.101313\n",
            "Epoch 18/100, Average Loss: 0.100910\n",
            "Epoch 19/100, Average Loss: 0.101174\n",
            "Epoch 20/100, Average Loss: 0.100923\n",
            "Epoch 21/100, Average Loss: 0.100352\n",
            "Epoch 22/100, Average Loss: 0.099975\n",
            "Epoch 23/100, Average Loss: 0.100115\n",
            "Epoch 24/100, Average Loss: 0.100032\n",
            "Epoch 25/100, Average Loss: 0.100035\n",
            "Epoch 26/100, Average Loss: 0.099532\n",
            "Epoch 27/100, Average Loss: 0.099450\n",
            "Epoch 28/100, Average Loss: 0.099312\n",
            "Epoch 29/100, Average Loss: 0.099213\n",
            "Epoch 30/100, Average Loss: 0.099539\n",
            "Epoch 31/100, Average Loss: 0.099263\n",
            "Epoch 32/100, Average Loss: 0.099355\n",
            "Epoch 33/100, Average Loss: 0.099249\n",
            "Epoch 34/100, Average Loss: 0.098826\n",
            "Epoch 35/100, Average Loss: 0.098898\n",
            "Epoch 36/100, Average Loss: 0.098610\n",
            "Epoch 37/100, Average Loss: 0.098782\n",
            "Epoch 38/100, Average Loss: 0.098414\n",
            "Epoch 39/100, Average Loss: 0.098658\n",
            "Epoch 40/100, Average Loss: 0.098233\n",
            "Epoch 41/100, Average Loss: 0.097967\n",
            "Epoch 42/100, Average Loss: 0.097742\n",
            "Epoch 43/100, Average Loss: 0.098055\n",
            "Epoch 44/100, Average Loss: 0.098047\n",
            "Epoch 45/100, Average Loss: 0.097706\n",
            "Epoch 46/100, Average Loss: 0.097800\n",
            "Epoch 47/100, Average Loss: 0.097576\n",
            "Epoch 48/100, Average Loss: 0.097298\n",
            "Epoch 49/100, Average Loss: 0.097102\n",
            "Epoch 50/100, Average Loss: 0.097192\n",
            "Epoch 51/100, Average Loss: 0.097081\n",
            "Epoch 52/100, Average Loss: 0.096987\n",
            "Epoch 53/100, Average Loss: 0.097462\n",
            "Epoch 54/100, Average Loss: 0.097511\n",
            "Epoch 55/100, Average Loss: 0.097188\n",
            "Epoch 56/100, Average Loss: 0.096980\n",
            "Epoch 57/100, Average Loss: 0.096854\n",
            "Epoch 58/100, Average Loss: 0.097226\n",
            "Epoch 59/100, Average Loss: 0.097337\n",
            "Epoch 60/100, Average Loss: 0.096858\n",
            "Epoch 61/100, Average Loss: 0.096525\n",
            "Epoch 62/100, Average Loss: 0.096797\n",
            "Epoch 63/100, Average Loss: 0.096283\n",
            "Epoch 64/100, Average Loss: 0.096364\n",
            "Epoch 65/100, Average Loss: 0.096519\n",
            "Epoch 66/100, Average Loss: 0.096746\n",
            "Epoch 67/100, Average Loss: 0.096264\n",
            "Epoch 68/100, Average Loss: 0.096491\n",
            "Epoch 69/100, Average Loss: 0.096590\n",
            "Epoch 70/100, Average Loss: 0.095981\n",
            "Epoch 71/100, Average Loss: 0.096325\n",
            "Epoch 72/100, Average Loss: 0.096483\n",
            "Epoch 73/100, Average Loss: 0.095924\n",
            "Epoch 74/100, Average Loss: 0.095897\n",
            "Epoch 75/100, Average Loss: 0.096140\n",
            "Epoch 76/100, Average Loss: 0.096240\n",
            "Epoch 77/100, Average Loss: 0.095823\n",
            "Epoch 78/100, Average Loss: 0.096086\n",
            "Epoch 79/100, Average Loss: 0.095778\n",
            "Epoch 80/100, Average Loss: 0.095401\n",
            "Epoch 81/100, Average Loss: 0.095990\n",
            "Epoch 82/100, Average Loss: 0.095780\n",
            "Epoch 83/100, Average Loss: 0.095717\n",
            "Epoch 84/100, Average Loss: 0.095620\n",
            "Epoch 85/100, Average Loss: 0.095642\n",
            "Epoch 86/100, Average Loss: 0.095587\n",
            "Epoch 87/100, Average Loss: 0.095550\n",
            "Epoch 88/100, Average Loss: 0.095237\n",
            "Epoch 89/100, Average Loss: 0.095431\n",
            "Epoch 90/100, Average Loss: 0.094658\n",
            "Epoch 91/100, Average Loss: 0.095497\n",
            "Epoch 92/100, Average Loss: 0.095350\n",
            "Epoch 93/100, Average Loss: 0.095577\n",
            "Epoch 94/100, Average Loss: 0.094866\n",
            "Epoch 95/100, Average Loss: 0.094860\n",
            "Epoch 96/100, Average Loss: 0.095186\n",
            "Epoch 97/100, Average Loss: 0.094806\n",
            "Epoch 98/100, Average Loss: 0.095224\n",
            "Epoch 99/100, Average Loss: 0.095069\n",
            "Epoch 100/100, Average Loss: 0.095333\n",
            "Training Time: 446.61 seconds\n",
            "Testing Time: 1.01 seconds\n",
            "Accuracy: 0.8627\n",
            "95% Confidence Interval: (0.8560, 0.8694)\n",
            "Confusion Matrix:\n",
            "[[ 911    0    8   15    5   15    7   14    1    4]\n",
            " [   0 1069   22    9    1    2    6    5   21    0]\n",
            " [  14    9  895   47   15    3   13   12   19    5]\n",
            " [   7    3   28  871    4   39    2   19   35    2]\n",
            " [   6    0    5    1  896    0    6   18    2   48]\n",
            " [  34    6    4  153   12  611   13    4   43   12]\n",
            " [  32    5   10    0   16   23  868    3    1    0]\n",
            " [   2    6   23   29   11    0    0  909    1   47]\n",
            " [  10   37   11   43   27   42    5    7  761   31]\n",
            " [  15    0    3   14   65    1    0   60   15  836]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import glob\n",
        "\n",
        "# Helper functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def one_hot_encode(labels, num_classes=10):\n",
        "    return np.eye(num_classes)[labels]\n",
        "\n",
        "def calculate_confidence_interval(accuracy, n, confidence=0.95):\n",
        "    Z = 1.96  # For 95% confidence level\n",
        "    ci_half_width = Z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - ci_half_width, accuracy + ci_half_width\n",
        "\n",
        "# Load data\n",
        "def load_data(file_path):\n",
        "    data = np.loadtxt(file_path)\n",
        "    X = data[:, 1:] / 255.0  # Normalize pixel values to [0, 1]\n",
        "    y = one_hot_encode(data[:, 0].astype(int))  # One-hot encode labels\n",
        "    return X, y\n",
        "\n",
        "# Initialize parameters\n",
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(hidden_size, input_size) * 0.01\n",
        "    b1 = np.zeros((hidden_size, 1))\n",
        "    W2 = np.random.randn(output_size, hidden_size) * 0.01\n",
        "    b2 = np.zeros((output_size, 1))\n",
        "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
        "\n",
        "# Forward pass\n",
        "def forward_propagation(X, parameters):\n",
        "    W1, b1, W2, b2 = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    return {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
        "\n",
        "# Compute least squares error\n",
        "def compute_loss(Y, A2):\n",
        "    return 0.5 * np.sum((Y - A2) ** 2)\n",
        "\n",
        "# Backpropagation\n",
        "def backpropagation(X, Y, forward_cache, parameters):\n",
        "    W2 = parameters[\"W2\"]\n",
        "    A1, A2 = forward_cache[\"A1\"], forward_cache[\"A2\"]\n",
        "\n",
        "    # Gradients\n",
        "    dZ2 = A2 - Y\n",
        "    dW2 = np.dot(dZ2, A1.T)\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dZ1 = np.dot(W2.T, dZ2) * sigmoid_derivative(A1)\n",
        "    dW1 = np.dot(dZ1, X.T)\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "\n",
        "# Update parameters\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    parameters[\"W1\"] -= learning_rate * grads[\"dW1\"]\n",
        "    parameters[\"b1\"] -= learning_rate * grads[\"db1\"]\n",
        "    parameters[\"W2\"] -= learning_rate * grads[\"dW2\"]\n",
        "    parameters[\"b2\"] -= learning_rate * grads[\"db2\"]\n",
        "    return parameters\n",
        "\n",
        "# Train neural network\n",
        "def train_neural_network(training_files, input_size, hidden_size, output_size, learning_rate, epochs):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
        "    average_losses = []\n",
        "\n",
        "    # Load all training data\n",
        "    X_train, Y_train = [], []\n",
        "    for file in training_files:\n",
        "        X, Y = load_data(file)\n",
        "        X_train.append(X)\n",
        "        Y_train.append(Y)\n",
        "    X_train = np.vstack(X_train)  # Combine all training data\n",
        "    Y_train = np.vstack(Y_train)  # Combine all training labels\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)  # Shuffle data indices for SGD\n",
        "\n",
        "        for idx in indices:\n",
        "            # Select a random sample\n",
        "            X_sample = X_train[idx].reshape(-1, 1)\n",
        "            Y_sample = Y_train[idx].reshape(-1, 1)\n",
        "\n",
        "            # Forward pass\n",
        "            forward_cache = forward_propagation(X_sample, parameters)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = compute_loss(Y_sample, forward_cache[\"A2\"])\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backpropagation\n",
        "            grads = backpropagation(X_sample, Y_sample, forward_cache, parameters)\n",
        "\n",
        "            # Update parameters\n",
        "            parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        average_loss = total_loss / X_train.shape[0]\n",
        "        average_losses.append(average_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {average_loss:.6f}\")\n",
        "\n",
        "    return parameters, average_losses\n",
        "\n",
        "# Test neural network\n",
        "def test_neural_network(testing_files, parameters):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for file in testing_files:\n",
        "        X, Y = load_data(file)\n",
        "        forward_cache = forward_propagation(X.T, parameters)\n",
        "        A2 = forward_cache[\"A2\"]\n",
        "        predicted_labels = np.argmax(A2, axis=0)\n",
        "        true_labels.extend(np.argmax(Y, axis=1))\n",
        "        predictions.extend(predicted_labels)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "    return accuracy, conf_matrix, true_labels, predictions\n",
        "\n",
        "# File paths\n",
        "# training_files = [f'content/data/train{i}.txt' for i in range(10)]\n",
        "# testing_files = [f'content/data/test{i}.txt' for i in range(10)]\n",
        "training_files = glob.glob('/content/data/train*.txt')\n",
        "testing_files = glob.glob('/content/data/test*.txt')\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 784\n",
        "hidden_size = 5\n",
        "output_size = 10\n",
        "learning_rate = 0.03\n",
        "epochs = 200\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "parameters, average_losses = train_neural_network(training_files, input_size, hidden_size, output_size, learning_rate, epochs)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Measure testing time\n",
        "start_test_time = time.time()\n",
        "accuracy, conf_matrix, true_labels, predictions = test_neural_network(testing_files, parameters)\n",
        "end_test_time = time.time()\n",
        "testing_time = end_test_time - start_test_time\n",
        "\n",
        "# Calculate confidence interval\n",
        "lower_ci, upper_ci = calculate_confidence_interval(accuracy, len(true_labels))\n",
        "\n",
        "# Results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Testing Time: {testing_time:.2f} seconds\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"95% Confidence Interval: ({lower_ci:.4f}, {upper_ci:.4f})\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot average loss per epoch\n",
        "plt.plot(average_losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Average Loss\")\n",
        "plt.title(\"Average Loss Over Epochs\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MEn3Hs1S4SNT",
        "outputId": "08f006f3-e524-4430-9bb2-15f1bdc627d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Average Loss: 0.189767\n",
            "Epoch 2/200, Average Loss: 0.124454\n",
            "Epoch 3/200, Average Loss: 0.115686\n",
            "Epoch 4/200, Average Loss: 0.112324\n",
            "Epoch 5/200, Average Loss: 0.110169\n",
            "Epoch 6/200, Average Loss: 0.108840\n",
            "Epoch 7/200, Average Loss: 0.108356\n",
            "Epoch 8/200, Average Loss: 0.107939\n",
            "Epoch 9/200, Average Loss: 0.107266\n",
            "Epoch 10/200, Average Loss: 0.106786\n",
            "Epoch 11/200, Average Loss: 0.105877\n",
            "Epoch 12/200, Average Loss: 0.105030\n",
            "Epoch 13/200, Average Loss: 0.104950\n",
            "Epoch 14/200, Average Loss: 0.104444\n",
            "Epoch 15/200, Average Loss: 0.104358\n",
            "Epoch 16/200, Average Loss: 0.104294\n",
            "Epoch 17/200, Average Loss: 0.103932\n",
            "Epoch 18/200, Average Loss: 0.102549\n",
            "Epoch 19/200, Average Loss: 0.103321\n",
            "Epoch 20/200, Average Loss: 0.103093\n",
            "Epoch 21/200, Average Loss: 0.101689\n",
            "Epoch 22/200, Average Loss: 0.102520\n",
            "Epoch 23/200, Average Loss: 0.101505\n",
            "Epoch 24/200, Average Loss: 0.101226\n",
            "Epoch 25/200, Average Loss: 0.101515\n",
            "Epoch 26/200, Average Loss: 0.101549\n",
            "Epoch 27/200, Average Loss: 0.101253\n",
            "Epoch 28/200, Average Loss: 0.100729\n",
            "Epoch 29/200, Average Loss: 0.100078\n",
            "Epoch 30/200, Average Loss: 0.100391\n",
            "Epoch 31/200, Average Loss: 0.100388\n",
            "Epoch 32/200, Average Loss: 0.100317\n",
            "Epoch 33/200, Average Loss: 0.100086\n",
            "Epoch 34/200, Average Loss: 0.099660\n",
            "Epoch 35/200, Average Loss: 0.099820\n",
            "Epoch 36/200, Average Loss: 0.099662\n",
            "Epoch 37/200, Average Loss: 0.099531\n",
            "Epoch 38/200, Average Loss: 0.100060\n",
            "Epoch 39/200, Average Loss: 0.099415\n",
            "Epoch 40/200, Average Loss: 0.099521\n",
            "Epoch 41/200, Average Loss: 0.099099\n",
            "Epoch 42/200, Average Loss: 0.099227\n",
            "Epoch 43/200, Average Loss: 0.098522\n",
            "Epoch 44/200, Average Loss: 0.098437\n",
            "Epoch 45/200, Average Loss: 0.098873\n",
            "Epoch 46/200, Average Loss: 0.098327\n",
            "Epoch 47/200, Average Loss: 0.098014\n",
            "Epoch 48/200, Average Loss: 0.097947\n",
            "Epoch 49/200, Average Loss: 0.098281\n",
            "Epoch 50/200, Average Loss: 0.098159\n",
            "Epoch 51/200, Average Loss: 0.098300\n",
            "Epoch 52/200, Average Loss: 0.098067\n",
            "Epoch 53/200, Average Loss: 0.098187\n",
            "Epoch 54/200, Average Loss: 0.097896\n",
            "Epoch 55/200, Average Loss: 0.097879\n",
            "Epoch 56/200, Average Loss: 0.097992\n",
            "Epoch 57/200, Average Loss: 0.097441\n",
            "Epoch 58/200, Average Loss: 0.097004\n",
            "Epoch 59/200, Average Loss: 0.097407\n",
            "Epoch 60/200, Average Loss: 0.097590\n",
            "Epoch 61/200, Average Loss: 0.097015\n",
            "Epoch 62/200, Average Loss: 0.096567\n",
            "Epoch 63/200, Average Loss: 0.096612\n",
            "Epoch 64/200, Average Loss: 0.096614\n",
            "Epoch 65/200, Average Loss: 0.096793\n",
            "Epoch 66/200, Average Loss: 0.096525\n",
            "Epoch 67/200, Average Loss: 0.096709\n",
            "Epoch 68/200, Average Loss: 0.096711\n",
            "Epoch 69/200, Average Loss: 0.096720\n",
            "Epoch 70/200, Average Loss: 0.096416\n",
            "Epoch 71/200, Average Loss: 0.096602\n",
            "Epoch 72/200, Average Loss: 0.096611\n",
            "Epoch 73/200, Average Loss: 0.096451\n",
            "Epoch 74/200, Average Loss: 0.095481\n",
            "Epoch 75/200, Average Loss: 0.096080\n",
            "Epoch 76/200, Average Loss: 0.095966\n",
            "Epoch 77/200, Average Loss: 0.095958\n",
            "Epoch 78/200, Average Loss: 0.095518\n",
            "Epoch 79/200, Average Loss: 0.095357\n",
            "Epoch 80/200, Average Loss: 0.095157\n",
            "Epoch 81/200, Average Loss: 0.095241\n",
            "Epoch 82/200, Average Loss: 0.094576\n",
            "Epoch 83/200, Average Loss: 0.095225\n",
            "Epoch 84/200, Average Loss: 0.095011\n",
            "Epoch 85/200, Average Loss: 0.094895\n",
            "Epoch 86/200, Average Loss: 0.095099\n",
            "Epoch 87/200, Average Loss: 0.094663\n",
            "Epoch 88/200, Average Loss: 0.094955\n",
            "Epoch 89/200, Average Loss: 0.095054\n",
            "Epoch 90/200, Average Loss: 0.095578\n",
            "Epoch 91/200, Average Loss: 0.095468\n",
            "Epoch 92/200, Average Loss: 0.094805\n",
            "Epoch 93/200, Average Loss: 0.094617\n",
            "Epoch 94/200, Average Loss: 0.094961\n",
            "Epoch 95/200, Average Loss: 0.094499\n",
            "Epoch 96/200, Average Loss: 0.094793\n",
            "Epoch 97/200, Average Loss: 0.094975\n",
            "Epoch 98/200, Average Loss: 0.095148\n",
            "Epoch 99/200, Average Loss: 0.095027\n",
            "Epoch 100/200, Average Loss: 0.094253\n",
            "Epoch 101/200, Average Loss: 0.094273\n",
            "Epoch 102/200, Average Loss: 0.094091\n",
            "Epoch 103/200, Average Loss: 0.094787\n",
            "Epoch 104/200, Average Loss: 0.094197\n",
            "Epoch 105/200, Average Loss: 0.094468\n",
            "Epoch 106/200, Average Loss: 0.093912\n",
            "Epoch 107/200, Average Loss: 0.094557\n",
            "Epoch 108/200, Average Loss: 0.093664\n",
            "Epoch 109/200, Average Loss: 0.094343\n",
            "Epoch 110/200, Average Loss: 0.093707\n",
            "Epoch 111/200, Average Loss: 0.093992\n",
            "Epoch 112/200, Average Loss: 0.093954\n",
            "Epoch 113/200, Average Loss: 0.093977\n",
            "Epoch 114/200, Average Loss: 0.093657\n",
            "Epoch 115/200, Average Loss: 0.093600\n",
            "Epoch 116/200, Average Loss: 0.093095\n",
            "Epoch 117/200, Average Loss: 0.093740\n",
            "Epoch 118/200, Average Loss: 0.093673\n",
            "Epoch 119/200, Average Loss: 0.093683\n",
            "Epoch 120/200, Average Loss: 0.093834\n",
            "Epoch 121/200, Average Loss: 0.093471\n",
            "Epoch 122/200, Average Loss: 0.093644\n",
            "Epoch 123/200, Average Loss: 0.093731\n",
            "Epoch 124/200, Average Loss: 0.092931\n",
            "Epoch 125/200, Average Loss: 0.093499\n",
            "Epoch 126/200, Average Loss: 0.093073\n",
            "Epoch 127/200, Average Loss: 0.092798\n",
            "Epoch 128/200, Average Loss: 0.092833\n",
            "Epoch 129/200, Average Loss: 0.093004\n",
            "Epoch 130/200, Average Loss: 0.093620\n",
            "Epoch 131/200, Average Loss: 0.092953\n",
            "Epoch 132/200, Average Loss: 0.092662\n",
            "Epoch 133/200, Average Loss: 0.092472\n",
            "Epoch 134/200, Average Loss: 0.093436\n",
            "Epoch 135/200, Average Loss: 0.092233\n",
            "Epoch 136/200, Average Loss: 0.092557\n",
            "Epoch 137/200, Average Loss: 0.093059\n",
            "Epoch 138/200, Average Loss: 0.093094\n",
            "Epoch 139/200, Average Loss: 0.092727\n",
            "Epoch 140/200, Average Loss: 0.092683\n",
            "Epoch 141/200, Average Loss: 0.092915\n",
            "Epoch 142/200, Average Loss: 0.092310\n",
            "Epoch 143/200, Average Loss: 0.092804\n",
            "Epoch 144/200, Average Loss: 0.092796\n",
            "Epoch 145/200, Average Loss: 0.092463\n",
            "Epoch 146/200, Average Loss: 0.092518\n",
            "Epoch 147/200, Average Loss: 0.092487\n",
            "Epoch 148/200, Average Loss: 0.092276\n",
            "Epoch 149/200, Average Loss: 0.092784\n",
            "Epoch 150/200, Average Loss: 0.092650\n",
            "Epoch 151/200, Average Loss: 0.092358\n",
            "Epoch 152/200, Average Loss: 0.092331\n",
            "Epoch 153/200, Average Loss: 0.092257\n",
            "Epoch 154/200, Average Loss: 0.092285\n",
            "Epoch 155/200, Average Loss: 0.092076\n",
            "Epoch 156/200, Average Loss: 0.092482\n",
            "Epoch 157/200, Average Loss: 0.091585\n",
            "Epoch 158/200, Average Loss: 0.091976\n",
            "Epoch 159/200, Average Loss: 0.091781\n",
            "Epoch 160/200, Average Loss: 0.092098\n",
            "Epoch 161/200, Average Loss: 0.092555\n",
            "Epoch 162/200, Average Loss: 0.092089\n",
            "Epoch 163/200, Average Loss: 0.091865\n",
            "Epoch 164/200, Average Loss: 0.092168\n",
            "Epoch 165/200, Average Loss: 0.092333\n",
            "Epoch 166/200, Average Loss: 0.092020\n",
            "Epoch 167/200, Average Loss: 0.091952\n",
            "Epoch 168/200, Average Loss: 0.092526\n",
            "Epoch 169/200, Average Loss: 0.091613\n",
            "Epoch 170/200, Average Loss: 0.091935\n",
            "Epoch 171/200, Average Loss: 0.091885\n",
            "Epoch 172/200, Average Loss: 0.091933\n",
            "Epoch 173/200, Average Loss: 0.091493\n",
            "Epoch 174/200, Average Loss: 0.091718\n",
            "Epoch 175/200, Average Loss: 0.091518\n",
            "Epoch 176/200, Average Loss: 0.092063\n",
            "Epoch 177/200, Average Loss: 0.091169\n",
            "Epoch 178/200, Average Loss: 0.090875\n",
            "Epoch 179/200, Average Loss: 0.091532\n",
            "Epoch 180/200, Average Loss: 0.091277\n",
            "Epoch 181/200, Average Loss: 0.091432\n",
            "Epoch 182/200, Average Loss: 0.091752\n",
            "Epoch 183/200, Average Loss: 0.091637\n",
            "Epoch 184/200, Average Loss: 0.091182\n",
            "Epoch 185/200, Average Loss: 0.091478\n",
            "Epoch 186/200, Average Loss: 0.091522\n",
            "Epoch 187/200, Average Loss: 0.091105\n",
            "Epoch 188/200, Average Loss: 0.091663\n",
            "Epoch 189/200, Average Loss: 0.091334\n",
            "Epoch 190/200, Average Loss: 0.091554\n",
            "Epoch 191/200, Average Loss: 0.091253\n",
            "Epoch 192/200, Average Loss: 0.091020\n",
            "Epoch 193/200, Average Loss: 0.091592\n",
            "Epoch 194/200, Average Loss: 0.091165\n",
            "Epoch 195/200, Average Loss: 0.091403\n",
            "Epoch 196/200, Average Loss: 0.090819\n",
            "Epoch 197/200, Average Loss: 0.090864\n",
            "Epoch 198/200, Average Loss: 0.091016\n",
            "Epoch 199/200, Average Loss: 0.091095\n",
            "Epoch 200/200, Average Loss: 0.091338\n",
            "Training Time: 874.03 seconds\n",
            "Testing Time: 0.96 seconds\n",
            "Accuracy: 0.8641\n",
            "95% Confidence Interval: (0.8574, 0.8708)\n",
            "Confusion Matrix:\n",
            "[[ 925    1    1   10    0   14   13    7    9    0]\n",
            " [   2 1055   11    1    0    0    3   11   50    2]\n",
            " [  14   20  815  109    7    6   18   18   18    7]\n",
            " [  13    2   24  886    1   23    2    8   19   32]\n",
            " [   0    4    0    2  878    5   12   11    6   64]\n",
            " [  22    0    9  127   15  604    9    4   90   12]\n",
            " [  25    9    3    1    9   22  850    2   37    0]\n",
            " [   8    5   21    8   13    0    1  900    3   69]\n",
            " [   9    9    2   50    7   25    8    0  849   15]\n",
            " [   5    0    0   21   70    4    2   17   11  879]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_custom_data(training_files, testing_files):\n",
        "    X_train, y_train, X_test, y_test = [], [], [], []\n",
        "\n",
        "    for file in training_files:\n",
        "        data = np.loadtxt(file)\n",
        "        X_train.append(data[:, 1:] / 255.0)  # Normalize pixel values to [0, 1]\n",
        "        y_train.append(data[:, 0].astype(int))\n",
        "\n",
        "    for file in testing_files:\n",
        "        data = np.loadtxt(file)\n",
        "        X_test.append(data[:, 1:] / 255.0)\n",
        "        y_test.append(data[:, 0].astype(int))\n",
        "\n",
        "    X_train = np.vstack(X_train)\n",
        "    y_train = np.hstack(y_train)\n",
        "    X_test = np.vstack(X_test)\n",
        "    y_test = np.hstack(y_test)\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train = to_categorical(y_train, num_classes=10)\n",
        "    y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# Define model\n",
        "def build_model(input_size, hidden_size, output_size):\n",
        "    model = Sequential([\n",
        "        Dense(hidden_size, activation='sigmoid', input_shape=(input_size,)),\n",
        "        Dense(output_size, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.02), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Calculate confidence interval\n",
        "def calculate_confidence_interval(accuracy, n, confidence=0.95):\n",
        "    Z = 1.96  # For 95% confidence level\n",
        "    ci_half_width = Z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "    return accuracy - ci_half_width, accuracy + ci_half_width\n",
        "\n",
        "# Main\n",
        "training_files = glob.glob('/content/data/train*.txt')\n",
        "testing_files = glob.glob('/content/data/test*.txt')\n",
        "\n",
        "X_train, y_train, X_test, y_test = load_custom_data(training_files, testing_files)\n",
        "\n",
        "input_size = 784  # 28x28 images flattened\n",
        "hidden_size = 5   # Number of hidden units\n",
        "output_size = 10  # Number of output classes (digits 0-9)\n",
        "\n",
        "# Build and train model\n",
        "model = build_model(input_size, hidden_size, output_size)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Measure testing time\n",
        "start_test_time = time.time()\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "end_test_time = time.time()\n",
        "testing_time = end_test_time - start_test_time\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate confidence interval\n",
        "lower_ci, upper_ci = calculate_confidence_interval(accuracy, len(y_test))\n",
        "\n",
        "# Results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Testing Time: {testing_time:.2f} seconds\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"95% Confidence Interval: ({lower_ci:.4f}, {upper_ci:.4f})\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy / Loss')\n",
        "plt.title('Training Performance')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QaX2SPzD96PW",
        "outputId": "5744c3f3-15fd-4195-ddcd-c9da7e1dce97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7444 - loss: 0.8948\n",
            "Epoch 2/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8504 - loss: 0.5298\n",
            "Epoch 3/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.5133\n",
            "Epoch 4/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.4985\n",
            "Epoch 5/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.4674\n",
            "Epoch 6/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8770 - loss: 0.4741\n",
            "Epoch 7/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.4775\n",
            "Epoch 8/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.4779\n",
            "Epoch 9/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8814 - loss: 0.4623\n",
            "Epoch 10/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8831 - loss: 0.4677\n",
            "Epoch 11/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.4580\n",
            "Epoch 12/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.4578\n",
            "Epoch 13/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.4544\n",
            "Epoch 14/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.4603\n",
            "Epoch 15/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.4647\n",
            "Epoch 16/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8879 - loss: 0.4489\n",
            "Epoch 17/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8879 - loss: 0.4633\n",
            "Epoch 18/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.4604\n",
            "Epoch 19/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.4487\n",
            "Epoch 20/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8916 - loss: 0.4485\n",
            "Epoch 21/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8906 - loss: 0.4482\n",
            "Epoch 22/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8881 - loss: 0.4570\n",
            "Epoch 23/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.4531\n",
            "Epoch 24/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.4454\n",
            "Epoch 25/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8904 - loss: 0.4533\n",
            "Epoch 26/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.4509\n",
            "Epoch 27/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.4446\n",
            "Epoch 28/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.4501\n",
            "Epoch 29/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.4442\n",
            "Epoch 30/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.4465\n",
            "Epoch 31/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.4461\n",
            "Epoch 32/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.4535\n",
            "Epoch 33/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.4471\n",
            "Epoch 34/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8929 - loss: 0.4437\n",
            "Epoch 35/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.4389\n",
            "Epoch 36/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8913 - loss: 0.4524\n",
            "Epoch 37/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 0.4461\n",
            "Epoch 38/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8919 - loss: 0.4433\n",
            "Epoch 39/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.4371\n",
            "Epoch 40/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.4410\n",
            "Epoch 41/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.4381\n",
            "Epoch 42/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.4396\n",
            "Epoch 43/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.4478\n",
            "Epoch 44/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.4469\n",
            "Epoch 45/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.4432\n",
            "Epoch 46/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.4388\n",
            "Epoch 47/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8953 - loss: 0.4376\n",
            "Epoch 48/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.4394\n",
            "Epoch 49/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8900 - loss: 0.4483\n",
            "Epoch 50/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8987 - loss: 0.4315\n",
            "Epoch 51/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.4326\n",
            "Epoch 52/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.4383\n",
            "Epoch 53/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.4403\n",
            "Epoch 54/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8965 - loss: 0.4387\n",
            "Epoch 55/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.4275\n",
            "Epoch 56/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.4339\n",
            "Epoch 57/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8951 - loss: 0.4388\n",
            "Epoch 58/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.4375\n",
            "Epoch 59/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.4332\n",
            "Epoch 60/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.4293\n",
            "Epoch 61/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.4394\n",
            "Epoch 62/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.4278\n",
            "Epoch 63/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8996 - loss: 0.4323\n",
            "Epoch 64/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.4379\n",
            "Epoch 65/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.4412\n",
            "Epoch 66/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.4373\n",
            "Epoch 67/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.4390\n",
            "Epoch 68/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.4213\n",
            "Epoch 69/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.4298\n",
            "Epoch 70/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.4345\n",
            "Epoch 71/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.4412\n",
            "Epoch 72/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.4278\n",
            "Epoch 73/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.4191\n",
            "Epoch 74/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.4285\n",
            "Epoch 75/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.4371\n",
            "Epoch 76/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.4363\n",
            "Epoch 77/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.4228\n",
            "Epoch 78/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.4306\n",
            "Epoch 79/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.4356\n",
            "Epoch 80/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.4260\n",
            "Epoch 81/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.4321\n",
            "Epoch 82/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.4270\n",
            "Epoch 83/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.4201\n",
            "Epoch 84/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.4265\n",
            "Epoch 85/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8969 - loss: 0.4349\n",
            "Epoch 86/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.4230\n",
            "Epoch 87/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.4279\n",
            "Epoch 88/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.4252\n",
            "Epoch 89/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8987 - loss: 0.4280\n",
            "Epoch 90/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.4301\n",
            "Epoch 91/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.4373\n",
            "Epoch 92/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.4157\n",
            "Epoch 93/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.4260\n",
            "Epoch 94/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.4278\n",
            "Epoch 95/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.4304\n",
            "Epoch 96/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.4208\n",
            "Epoch 97/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.4309\n",
            "Epoch 98/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.4245\n",
            "Epoch 99/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.4173\n",
            "Epoch 100/100\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.4221\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Training Time: 392.53 seconds\n",
            "Testing Time: 0.68 seconds\n",
            "Accuracy: 0.8883\n",
            "95% Confidence Interval: (0.8821, 0.8945)\n",
            "Confusion Matrix:\n",
            "[[ 932    0    2    0    3    3   27    6    7    0]\n",
            " [   0 1092    8    3    0    2    4    0   25    1]\n",
            " [  35    8  853   11   14    1   17   18   74    1]\n",
            " [   1   15   27  777    1  119    2   34   31    3]\n",
            " [   1    6    2    0  940    0   12    5    4   12]\n",
            " [  14    0    4   35    9  730   21    6   62   11]\n",
            " [  12    2    3    0   16    7  898    0   20    0]\n",
            " [   2   12   18    3   17    1    1  939    7   28]\n",
            " [  18   15    7    3   11   18   13    6  867   16]\n",
            " [   8    2    1    1   77   18    0   38    9  855]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD, Adadelta\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dropout, MaxPool2D, AveragePooling2D, MaxPooling2D\n",
        "from keras import backend as k\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_rows, img_cols=28, 28\n",
        "\n",
        "if k.image_data_format() == 'channels_first':\n",
        "     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "     npx = (1, img_rows, img_cols)\n",
        "\n",
        "else:\n",
        "     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "     inpx = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "inpx = Input(shape=(28, 28, 1))  # The input shape should include the channel dimension\n",
        "\n",
        "# Define the layers\n",
        "x = Conv2D(6, kernel_size=(5, 5))(inpx)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = AveragePooling2D(pool_size =(2,2))(x)\n",
        "\n",
        "x = Conv2D(16, kernel_size=(3,3))(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(120, kernel_size=(5, 5))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(84)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dense(10)(x)\n",
        "x = Activation(\"softmax\")(x)\n",
        "model = Model(inpx, x)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=SGD(learning_rate=0.01), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=100,validation_data=(x_test, y_test))\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "predictions = model.predict(x_test)\n",
        "testing_time = time.time() - start_time\n",
        "\n",
        "y_predicted_labels = [np.argmax(i) for i in predictions]\n",
        "y_true_labels = [np.argmax(i) for i in y_test]\n",
        "confusion = confusion_matrix(y_true_labels,y_predicted_labels)\n",
        "accuracy = accuracy_score(y_true_labels, y_predicted_labels)\n",
        "\n",
        "# Calculate 95% confidence interval for accuracy\n",
        "n = len(y_true_labels)\n",
        "z = 1.96  # For 95% confidence interval\n",
        "conf_interval = z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
        "\n",
        "# Display results\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"95% Confidence Interval: [{(accuracy - conf_interval) * 100:.2f}%, {(accuracy + conf_interval) * 100:.2f}%]\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Testing Time: {testing_time:.2f} seconds\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v2E7_fqBMLPF",
        "outputId": "9c5dc478-db22-42eb-c581-09b11b275f40"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_53 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_25                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_54 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_26                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m120\u001b[0m)           │          \u001b[38;5;34m48,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │          \u001b[38;5;34m10,164\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_55 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m850\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_56 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_25                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_26                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,170\u001b[0m (235.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,170</span> (235.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,170\u001b[0m (235.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,170</span> (235.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.4072 - loss: 1.9752 - val_accuracy: 0.8744 - val_loss: 0.4197\n",
            "Epoch 2/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.8815 - loss: 0.3922 - val_accuracy: 0.9004 - val_loss: 0.3286\n",
            "Epoch 3/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.9111 - loss: 0.3011 - val_accuracy: 0.9279 - val_loss: 0.2404\n",
            "Epoch 4/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 38ms/step - accuracy: 0.9215 - loss: 0.2543 - val_accuracy: 0.9314 - val_loss: 0.2226\n",
            "Epoch 5/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9342 - loss: 0.2180 - val_accuracy: 0.9449 - val_loss: 0.1793\n",
            "Epoch 6/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9414 - loss: 0.1963 - val_accuracy: 0.9499 - val_loss: 0.1645\n",
            "Epoch 7/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9480 - loss: 0.1739 - val_accuracy: 0.9579 - val_loss: 0.1419\n",
            "Epoch 8/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9548 - loss: 0.1550 - val_accuracy: 0.9614 - val_loss: 0.1348\n",
            "Epoch 9/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9576 - loss: 0.1440 - val_accuracy: 0.9629 - val_loss: 0.1235\n",
            "Epoch 10/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9606 - loss: 0.1327 - val_accuracy: 0.9627 - val_loss: 0.1264\n",
            "Epoch 11/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9631 - loss: 0.1266 - val_accuracy: 0.9662 - val_loss: 0.1153\n",
            "Epoch 12/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9653 - loss: 0.1165 - val_accuracy: 0.9686 - val_loss: 0.1030\n",
            "Epoch 13/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9658 - loss: 0.1111 - val_accuracy: 0.9698 - val_loss: 0.0960\n",
            "Epoch 14/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9680 - loss: 0.1059 - val_accuracy: 0.9682 - val_loss: 0.1037\n",
            "Epoch 15/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9703 - loss: 0.0994 - val_accuracy: 0.9710 - val_loss: 0.0893\n",
            "Epoch 16/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9722 - loss: 0.0909 - val_accuracy: 0.9724 - val_loss: 0.0888\n",
            "Epoch 17/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9737 - loss: 0.0891 - val_accuracy: 0.9743 - val_loss: 0.0831\n",
            "Epoch 18/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9742 - loss: 0.0877 - val_accuracy: 0.9747 - val_loss: 0.0850\n",
            "Epoch 19/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9753 - loss: 0.0840 - val_accuracy: 0.9759 - val_loss: 0.0788\n",
            "Epoch 20/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.9773 - loss: 0.0765 - val_accuracy: 0.9746 - val_loss: 0.0794\n",
            "Epoch 21/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9769 - loss: 0.0753 - val_accuracy: 0.9748 - val_loss: 0.0781\n",
            "Epoch 22/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9789 - loss: 0.0713 - val_accuracy: 0.9759 - val_loss: 0.0737\n",
            "Epoch 23/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9788 - loss: 0.0684 - val_accuracy: 0.9763 - val_loss: 0.0752\n",
            "Epoch 24/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 39ms/step - accuracy: 0.9799 - loss: 0.0679 - val_accuracy: 0.9768 - val_loss: 0.0742\n",
            "Epoch 25/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.9798 - loss: 0.0685 - val_accuracy: 0.9787 - val_loss: 0.0687\n",
            "Epoch 26/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 36ms/step - accuracy: 0.9798 - loss: 0.0682 - val_accuracy: 0.9762 - val_loss: 0.0738\n",
            "Epoch 27/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9799 - loss: 0.0648 - val_accuracy: 0.9784 - val_loss: 0.0681\n",
            "Epoch 28/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 36ms/step - accuracy: 0.9812 - loss: 0.0624 - val_accuracy: 0.9791 - val_loss: 0.0688\n",
            "Epoch 29/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9813 - loss: 0.0605 - val_accuracy: 0.9802 - val_loss: 0.0626\n",
            "Epoch 30/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9831 - loss: 0.0586 - val_accuracy: 0.9785 - val_loss: 0.0657\n",
            "Epoch 31/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.9834 - loss: 0.0577 - val_accuracy: 0.9789 - val_loss: 0.0655\n",
            "Epoch 32/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 37ms/step - accuracy: 0.9838 - loss: 0.0559 - val_accuracy: 0.9803 - val_loss: 0.0641\n",
            "Epoch 33/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - accuracy: 0.9833 - loss: 0.0568 - val_accuracy: 0.9798 - val_loss: 0.0641\n",
            "Epoch 34/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9835 - loss: 0.0556 - val_accuracy: 0.9801 - val_loss: 0.0616\n",
            "Epoch 35/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9845 - loss: 0.0502 - val_accuracy: 0.9779 - val_loss: 0.0688\n",
            "Epoch 36/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - accuracy: 0.9846 - loss: 0.0507 - val_accuracy: 0.9806 - val_loss: 0.0597\n",
            "Epoch 37/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 37ms/step - accuracy: 0.9850 - loss: 0.0490 - val_accuracy: 0.9803 - val_loss: 0.0657\n",
            "Epoch 38/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9841 - loss: 0.0493 - val_accuracy: 0.9813 - val_loss: 0.0590\n",
            "Epoch 39/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.9850 - loss: 0.0496 - val_accuracy: 0.9819 - val_loss: 0.0584\n",
            "Epoch 40/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 38ms/step - accuracy: 0.9865 - loss: 0.0459 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 41/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9846 - loss: 0.0488 - val_accuracy: 0.9826 - val_loss: 0.0550\n",
            "Epoch 42/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9861 - loss: 0.0455 - val_accuracy: 0.9821 - val_loss: 0.0569\n",
            "Epoch 43/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - accuracy: 0.9861 - loss: 0.0461 - val_accuracy: 0.9808 - val_loss: 0.0584\n",
            "Epoch 44/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.9869 - loss: 0.0434 - val_accuracy: 0.9829 - val_loss: 0.0585\n",
            "Epoch 45/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.9874 - loss: 0.0418 - val_accuracy: 0.9823 - val_loss: 0.0554\n",
            "Epoch 46/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.9865 - loss: 0.0431 - val_accuracy: 0.9834 - val_loss: 0.0532\n",
            "Epoch 47/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - accuracy: 0.9868 - loss: 0.0414 - val_accuracy: 0.9814 - val_loss: 0.0563\n",
            "Epoch 48/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 37ms/step - accuracy: 0.9875 - loss: 0.0414 - val_accuracy: 0.9841 - val_loss: 0.0537\n",
            "Epoch 49/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 38ms/step - accuracy: 0.9878 - loss: 0.0384 - val_accuracy: 0.9827 - val_loss: 0.0548\n",
            "Epoch 50/50\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.9886 - loss: 0.0390 - val_accuracy: 0.9833 - val_loss: 0.0534\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "Accuracy: 98.33%\n",
            "95% Confidence Interval: [98.08%, 98.58%]\n",
            "Training Time: 1686.10 seconds\n",
            "Testing Time: 1.83 seconds\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 970    0    1    0    1    0    5    1    2    0]\n",
            " [   0 1130    2    0    0    1    1    0    1    0]\n",
            " [   3    0 1014    2    1    0    1    5    6    0]\n",
            " [   0    0    0  997    0    8    0    2    3    0]\n",
            " [   1    0    0    0  971    0    4    2    0    4]\n",
            " [   2    1    1    4    1  872    4    1    4    2]\n",
            " [   4    3    0    0    4    1  946    0    0    0]\n",
            " [   0    3    4    1    1    0    0 1014    2    3]\n",
            " [   5    0    3    2    1    3    2    7  950    1]\n",
            " [   1    5    1    4   12    2    1   12    2  969]]\n"
          ]
        }
      ]
    }
  ]
}